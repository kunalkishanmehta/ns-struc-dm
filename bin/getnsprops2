#!/usr/bin/python
__doc__ = 'GETNSPROPS -- calculate NS properties as a function of central density for selected EoSs'
__usage__ = 'getnsprops EoS1.csv,EoS2.csv,... [-v] [-p R,M,Lambda,...] [-n 200] [-r 0.8,12] [-d ./eos/] [-o ./dat/]'
__author__ = 'philippe.landry@ligo.org'
__date__ = '03-2019'

import numpy as np
from optparse import OptionParser
from scipy.interpolate import interp1d
from nsstruc.tov import tov
from nsstruc.constants import *
import scipy.interpolate
from scipy.optimize import curve_fit
from scipy.interpolate import interp1d
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import h5py
import pandas as pd
import json
import pickle
import marshal
import gc
import hdfdict
# from nsstruc.pltsetup import *


parser = OptionParser(usage=__usage__, description=__doc__)
parser.add_option('-p', '--props', default='R,M,Lambda', help='comma-separated list of NS properties to calculate, DEFAULT=R,M,Lambda', metavar='R,M,Lambda')
parser.add_option('-n', '--numrhoc', default=2e2, help='number of central densities to sample per EoS, DEFAULT=200', metavar='2e2')
parser.add_option('-r', '--rhorng', default='0.8,1.2e1', help='comma-separated min and max values for central density in units of rhonuc, DEFAULT=0.8,1.2e1', metavar='0.8,1.2e1')
parser.add_option('-R', '--rhodmrng', default='0.8,1.2e1', help='comma-separated min and max values for central dark matter density in units of rhonuc, DEFAULT=0.8,1.2e1', metavar='0.8,1.2e1')
parser.add_option('-s', '--stpi', default=1e1, help='starting step size for radial TOV integration in cm, DEFAULT=1e1', metavar='1e1')
parser.add_option('-N', '--numpts', default=2e3, help='number of points for radial TOV integration, DEFAULT=2e3', metavar='2e3')
parser.add_option('-m', '--maxr', default=2e6, help='radius endpoint in cm for surface finding algorithm, DEFAULT=2e6', metavar='2e6')
parser.add_option('-T', '--tol', default=1e1, help='pressure tolerance for surface finding algorithm in g/cm^3, DEFAULT=1e1', metavar='1e1')
parser.add_option('-d', '--dir', default='./eos/', help='path to directory housing EoS data, DEFAULT=./eos/', metavar='./eos/')
parser.add_option('-o', '--outdir', default='./dat/', help='path to output directory, DEFAULT=./dat/', metavar='./dat/')
parser.add_option('-t', '--tag', default='macro-', help='tag for output data file, DEFAULT=macro-', metavar='macro-')
parser.add_option('-v', '--verbose', action='store_true', default=False, help='toggle verbose output, DEFAULT=False', metavar='False')

opts, args = parser.parse_args()
eosnames = str(args[0]).split(',')
props = str(opts.props).split(',')
numprops = len(props)
rhorng = str(opts.rhorng).split(',')
rhodmrng = str(opts.rhodmrng).split(',')

if len(rhorng) >2:
	rhocord = [float(rho) for rho in rhorng]
else:
	rhoi, rhof = [float(rho) for rho in rhorng]

if len(rhodmrng) >2:
	rhodmcord = [float(rho) for rho in rhodmrng]
else:
	rhodmi, rhodmf = [float(rho) for rho in rhodmrng]
numrhoc = int(float(opts.numrhoc))
stp = float(opts.stpi)
numpts = int(float(opts.numpts))
maxr = float(opts.maxr)
tol = float(opts.tol)
indir = str(opts.dir)
outdir = str(opts.outdir)
tag = str(opts.tag)
verb = opts.verbose

# CALCULATE NS PROPERTIES FOR EACH EOS

# def Solver(eos,props = 'R,M,Lambda'):

for eosname in eosnames:

	shortname = (eosname.split('.')[0]).split('eos-')[-1]
	if verb == True: print('Calculate properties of ' + str(shortname) + ' stars')

	eospath = indir+eosname
# 	eospath2 = str(eos)
	outfile = open(outdir+tag+shortname+".csv","w")
	outfile.write('rhoc,rhocdm,' + ','.join(props) + ',Mg,fdm \n')

	eosdat = np.genfromtxt(eospath,names=True,delimiter=',')
	rhodat = eosdat['baryon_density'] # rest-mass energy density in units of g/cm^3
	pdat = eosdat['pressurec2'] # pressure in units of g/cm^3
	mudat = eosdat['energy_densityc2'] # total energy density in units of g/cm^3

	rhop = interp1d(pdat,rhodat,kind='linear',bounds_error=False,fill_value=0)
	def Rho(p): return rhop(p)

	mup = interp1d(pdat,mudat,kind='linear',bounds_error=False,fill_value=0)
	def mu(p): return mup(p)

	prho = interp1d(rhodat,pdat,kind='linear',bounds_error=False,fill_value=0)
	def P(rho): return prho(rho)

	cs2pi = interp1d(pdat,np.gradient(mudat,pdat),kind='linear', bounds_error=False, fill_value=0)
	def cs2i(p): return cs2pi(p) # 1/sound speed squared
	if len(rhorng) >2:
		rhocs = rhocord
		properties = np.zeros((len(rhorng), numprops+4))
	else:
		rhocs = np.linspace(max(rhoi*rhonuc,rhodat[0]),min(rhof*rhonuc,rhodat[-1]),numrhoc)
		properties = np.zeros((numrhoc**2, numprops+4))
	if len(rhodmrng) >2:
		rhocdms = rhodmcord
		properties = np.zeros((len(rhodmrng), numprops+4))
	else:
		rhocdms = np.linspace(max(rhodmi*rhonuc,rhodat[0]),min(rhodmf*rhonuc,rhodat[-1]),numrhoc)
		properties = np.zeros((numrhoc**2, numprops+4))


	i = 0
	if verb == True: print('Start at central density {0} g/cm^3'.format(rhocs[0]))

	if len(rhorng) >2:
		for rhoc,rhocdm in zip(rhocs,rhocdms): # compute macroscopic properties for star of each central density
			macro = tov([mu,P,cs2i,Rho],rhoc, rhocdm, props,stp,numpts,maxr,tol)
			properties[i] = [item for List in [[rhoc],[rhocdm],macro] for item in List] + [macro[props.index('Mdm')]+macro[props.index('M')],macro[props.index('Md')]/(macro[props.index('Mb')]+macro[props.index('Md')])]
			i = i+1
	else:
		for rhoc in rhocs: # compute macroscopic properties for star of each central density
			for rhocdm in rhocdms:
				macro = tov([mu,P,cs2i,Rho],rhoc, rhocdm, props,stp,numpts,maxr,tol)
				properties[i] = [item for List in [[rhoc],[rhocdm],macro] for item in List] + [macro[props.index('Mdm')]+macro[props.index('M')],macro[props.index('Md')]/(macro[props.index('Mb')]+macro[props.index('Md')])]
				i = i+1

	if verb == True: print 'Done at central density {0} g/cm^3\nSave to '.format(rhocs[-1])+outdir+tag+shortname+'.csv'

	np.savetxt(outfile,properties,delimiter=',')
# 	header = ['rhoc', 'rhocdm', 'R', 'M', 'Rdm','Mdm','Mb', 'Md', 'Mg', 'fdm' ]
# 	properties2 = pd.DataFrame(properties, columns = header)

	headers = ('rhoc,rhocdm,'+','.join(props) + ',Mg,fdm').split(',')
	#properties[headers.index('rhoc')]



# to associate the dark matter fraction to each point in rhoc-rhocdm space, interpolate 3D (rhoc,rhocdm,fdm) data to get a function fdm(rhoc,rhocdm)
x = properties[:, headers.index('rhoc')]  # Input data from 'rhoc' column
y = properties[:, headers.index('rhocdm')]  # Input data from 'rhocdm' column
z = properties[:, headers.index('fdm')]  # Input data from 'fdm' column

X = np.linspace(0.1e14,3.1e15,1000) # the grid where we'll evaluate fdm(rhoc,rhocdm)
Y = np.linspace(0.1e14,3.1e15,1000)
x_grid, y_grid = np.meshgrid(X, Y)


outdat = scipy.interpolate.griddata((x,y),z,(x_grid,y_grid),'linear') #, rescale=True
#  # fdm evaluated on the grid, with one of three methods: nearest, linear, cubic

num_cs = 9


cs = plt.contour(x_grid,y_grid,outdat,list(np.geomspace(1e-2,0.1,2))+list(np.linspace(0.1,0.9,num_cs)[1:])+list(reversed(1.-np.geomspace(1e-2,0.1,2)[:-1])),colors='r') # plot the contours of constant fdm(rhoc,rhocdm)
# plt.scatter(x, y, marker='.', s=3)  # overlay the rhoc-rhocdm scatter points for comparison


# plt.xlabel('rho_c [g/cm^3]')
# plt.ylabel('rho_c^DM [g/cm^3]')

# # Save the plot as an image file
# plt.savefig('plot_fdm.png')
plt.close()

contours = []
for i in range(num_cs+3):
  try: c = cs.allsegs[i][0] # if a contour was plotted, save it
  except: continue
  contours += [c] # list that stores all the extracted contours

# downsample the contours to get a list of (rhoc,rhocdm) coordinates to use to generate a constant-fdm sequence of stars

num_stars = 100 # how many stars to aim for in the sequence
rhocs, rhocdms = [], []



for c in contours:

  skip = int(len(c[:,0])/num_stars)
  rhocs += [c[::skip,0]]
  rhocdms += [c[::skip,1]] # downselect to num_stars (rhoc,rhocdm) points


rhomin = 2.8e14 # because some central densities are too small to give physical neutron stars, throw out those below rhomin
rhomax = 12*rhomin # because some central densities are too large to give physical neutron stars, throw out those above rhomax
rhocs_out, rhocdms_out = [], []

for c,cdm in zip(rhocs,rhocdms):
  c_out, cdm_out = [], []

  for rhoc,rhocdm in zip(c,cdm):

    if (rhoc >= rhomin or rhocdm >= rhomin) and rhoc <= rhomax and rhocdm <=rhomax: # one of rhoc/rhocdm below rhomin is ok, to allow pure regular matter or pure dm star
      c_out += [rhoc]
      cdm_out += [rhocdm]
  rhocs_out += [c_out]
  rhocdms_out += [cdm_out]

def find_rhos(n):
  newrhoc = rhocs_out[n]


  newrhocdm = rhocdms_out[n]

  return newrhoc, newrhocdm

dict_properties = {}

contour_fdm = list(np.geomspace(1e-2, 0.1, 2)) + list(np.linspace(0.1, 0.9, len(contours))[1:]) + list(reversed(1. - np.geomspace(1e-2, 0.1, 2)[:-1]))

for i in range(len(contours)):
    print('loop 1 i=', i)
    newrhocslist, newrhocdmlist = find_rhos(i)

    newproperties = np.zeros((len(newrhocslist)*len(newrhocdmlist), numprops+4))
    j = 0
    for rhoc, rhocdm in zip(newrhocslist, newrhocdmlist):
        macro = tov([mu, P, cs2i, Rho], rhoc, rhocdm, props, stp, numpts, maxr, tol)
        newproperties[j] = [item for List in [[rhoc], [rhocdm], macro] for item in List] + [macro[props.index('Mdm')] + macro[props.index('M')], macro[props.index('Md')]/(macro[props.index('Mb')] + macro[props.index('Md')])]
        j = j + 1
    dict_properties['contour_fdm'][str(i+1)] = pd.DataFrame(newproperties, columns=headers)




# #
# #
# #
# #
# #
# #

# # to associate the (dark) baryon mass to each point in rhoc-rhocdm space, interpolate 3D (rhoc,rhocdm,Mb) data to get a function Mb(rhoc,rhocdm)

# x = properties[:, headers.index('rhoc')]  # Input data from 'R' column
# y = properties[:, headers.index('rhocdm')]  # Input data from 'rhocdm' column
# z = properties[:, headers.index('Mb')]  # Input data from 'Mb' column
# zdm = properties[:, headers.index('Md')]  # Input data from 'Md' column

# X = np.linspace(0.1e14,3.1e15,1000) # the grid where we'll evaluate Mb(rhoc,rhocdm)
# Y = np.linspace(0.1e14,3.1e15,1000)
# x_grid, y_grid = np.meshgrid(X, Y)

# outdat = scipy.interpolate.griddata((x,y),z,(x_grid,y_grid),'linear') # Mb evaluated on the grid, with one of three methods: nearest, linear, cubic
# outdat_dm = scipy.interpolate.griddata((x,y),zdm,(x_grid,y_grid),'linear') # Md evaluated on the grid

# # plot the interpolated Mb and Md functions

# plt.pcolormesh(x_grid,y_grid,outdat,cmap='gray_r') # show Mb(rhoc,rhocdm) as a color map (darker = larger Mb)
# #plt.pcolormesh(x_grid,y_grid,outdat,cmap='gray_r') # show Md(rhoc,rhocdm) as a color map (darker = larger Mb) -- but can't seem to show two colormaps at once

# num_cs = 11
# cs = plt.contour(x_grid,y_grid,outdat,list(np.linspace(1.,3.,num_cs)),colors='r') # plot the contours of constant Mb(rhoc,rhocdm)
# # cs_dm = plt.contour(x_grid,y_grid,outdat_dm,list(np.linspace(1.,3.,num_cs)),colors='g') # plot the contours of constant Md(rhoc,rhocdm)

# plt.xlabel('rho_c [g/cm^3]')
# plt.ylabel('rho_c^DM [g/cm^3]')

# # Save the plot as an image file
# plt.savefig('plot_md.png')

# plt.close()

# # Count the number of contour lines for cs
# num_contour_lines = 0
# for collection in cs.collections:
#     num_contour_lines += len(collection.get_paths())


# # extract the (rhoc,rhocdm) coordinates of the constant-fdm contours

# contours = []
# for i in range(num_cs+3):
#   try: c = cs.allsegs[i][0] # if a contour was plotted, save it
#   except: continue
#   contours += [c] # list that stores all the extracted contours

# # downsample the contours to get a list of (rhoc,rhocdm) coordinates to use to generate a constant-fdm sequence of stars

# num_stars = 100 # how many stars to aim for in the sequence
# rhocs, rhocdms = [], []

# for c in contours:

#   skip = int(len(c[:,0])/num_stars)
#   rhocs += [c[::skip,0]]
#   rhocdms += [c[::skip,1]] # downselect to num_stars (rhoc,rhocdm) points


# rhomin = 2.8e14 # because some central densities are too small to give physical neutron stars, throw out those below rhomin
# rhomax = 12*rhomin # because some central densities are too large to give physical neutron stars, throw out those above rhomax
# rhocs_out, rhocdms_out = [], []

# for c,cdm in zip(rhocs,rhocdms):
#   c_out, cdm_out = [], []

#   for rhoc,rhocdm in zip(c,cdm):

#     if (rhoc >= rhomin or rhocdm >= rhomin) and rhoc <= rhomax and rhocdm <=rhomax: # one of rhoc/rhocdm below rhomin is ok, to allow pure regular matter or pure dm star
#       c_out += [rhoc]
#       cdm_out += [rhocdm]
#   rhocs_out += [c_out]
#   rhocdms_out += [cdm_out]

# # plot the interpolated Mb and Md functions

# plt.pcolormesh(x_grid,y_grid,outdat,cmap='gray_r') # show Mb(rhoc,rhocdm) as a color map (darker = larger Mb)
# #plt.pcolormesh(x_grid,y_grid,outdat,cmap='gray_r') # show Md(rhoc,rhocdm) as a color map (darker = larger Mb) -- but can't seem to show two colormaps at once

# contour_mb = list(np.geomspace(1e-2, 0.1, 2)) + list(np.linspace(0.1, 0.9, len(contours))[1:]) + list(reversed(1. - np.geomspace(1e-2, 0.1, 2)[:-1]))

# for i in range(len(contours)):
# 	print('loop 2 i=', i)
# 	newrhocslist, newrhocdmlist = find_rhos(i)

# 	newproperties = np.zeros((len(newrhocslist), numprops+4))
# 	j=0
# 	for rhoc,rhocdm in zip(newrhocslist,newrhocdmlist):
# 		macro = tov([mu,P,cs2i,Rho],rhoc, rhocdm, props,stp,numpts,maxr,tol)
# 		newproperties[j] = [item for List in [[rhoc],[rhocdm],macro] for item in List] + [macro[props.index('Mdm')]+macro[props.index('M')],macro[props.index('Md')]/(macro[props.index('Mb')]+macro[props.index('Md')])]
# 		j = j+1
# 	dict_properties['contour_mb'] = pd.DataFrame(newproperties, columns=headers)









# def find_max(file):
#   l = np.argmax((file['Mg']))
#   R, M, rho_c, rho_cdm = file['R'][l], file['Mg'][l], file['rhoc'][l], file['rhocdm'][l]
#   return R,M, rho_c, rho_cdm



# # to associate the (dark) baryon mass to each point in rhoc-rhocdm space, interpolate 3D (rhoc,rhocdm,Mb) data to get a function Mb(rhoc,rhocdm)

# x = properties[:, headers.index('rhoc')]  # Input data from 'R' column
# y = properties[:, headers.index('rhocdm')]  # Input data from 'rhocdm' column
# z = properties[:, headers.index('Mb')]  # Input data from 'Mb' column
# zdm = properties[:, headers.index('Md')]  # Input data from 'Md' column

# X = np.linspace(0.1e14,3.1e15,1000) # the grid where we'll evaluate Mb(rhoc,rhocdm)
# Y = np.linspace(0.1e14,3.1e15,1000)
# x_grid, y_grid = np.meshgrid(X, Y)


# outdat_dm = scipy.interpolate.griddata((x,y),zdm,(x_grid,y_grid),'linear') # Md evaluated on the grid


# plt.pcolormesh(x_grid,y_grid,outdat,cmap='gray_r') # show Mb(rhoc,rhocdm) as a color map (darker = larger Mb)
# #plt.pcolormesh(x_grid,y_grid,outdat,cmap='gray_r') # show Md(rhoc,rhocdm) as a color map (darker = larger Mb) -- but can't seem to show two colormaps at once

# num_cs = 11

# cs_dm = plt.contour(x_grid,y_grid,outdat_dm,list(np.linspace(1.,3.,num_cs)),colors='g') # plot the contours of constant Md(rhoc,rhocdm)

# # plt.xlabel('rho_c [g/cm^3]')
# # plt.ylabel('rho_c^DM [g/cm^3]')

# # # Save the plot as an image file
# # plt.savefig('plot_mb.png')

# # plt.close()

# # Count the number of contour lines for cs_dm
# num_contour_lines_dm = 0
# for collection in cs_dm.collections:
#     num_contour_lines_dm += len(collection.get_paths())



# contours_dm = []
# for i in range(num_cs+1):
#   try: c = cs_dm.allsegs[i][0] # if a contour was plotted, save it
#   except: continue
#   contours_dm += [c] # list that stores all the extracted contours

# for c_dm in contours_dm: plt.plot(c_dm[:,0],c_dm[:,1],color='g') # plot the extracted contours

# # plt.scatter(dat['rhoc'],dat['rhocdm'],marker='.',s=3,c='k') # overlay scatter points

# # plt.xlabel('rho_c [g/cm^3]')
# # plt.ylabel('rho_c^DM [g/cm^3]')


# # downsample the contours to get a list of (rhoc,rhocdm) coordinates to use to generate a constant-fdm sequence of stars

# num_stars = 100 # how many stars to aim for in the sequence
# rhocs, rhocdms = [], []

# for c in contours_dm:

#   skip = int(len(c[:,0])/num_stars)
#   rhocs += [c[::skip,0]]
#   rhocdms += [c[::skip,1]] # downselect to num_stars (rhoc,rhocdm) points


# rhomin = 2.8e14 # because some central densities are too small to give physical neutron stars, throw out those below rhomin
# rhomax = 12*rhomin # because some central densities are too large to give physical neutron stars, throw out those above rhomax
# rhocs_out, rhocdms_out = [], []

# for c,cdm in zip(rhocs,rhocdms):
#   c_out, cdm_out = [], []

#   for rhoc,rhocdm in zip(c,cdm):

#     if (rhoc >= rhomin or rhocdm >= rhomin) and rhoc <= rhomax and rhocdm <=rhomax: # one of rhoc/rhocdm below rhomin is ok, to allow pure regular matter or pure dm star
#       c_out += [rhoc]
#       cdm_out += [rhocdm]
#   rhocs_out += [c_out]
#   rhocdms_out += [cdm_out]

# contour_md = list(np.geomspace(1e-2, 0.1, 2)) + list(np.linspace(0.1, 0.9, len(contours_dm))[1:]) + list(reversed(1. - np.geomspace(1e-2, 0.1, 2)[:-1]))


# #run the TOV solver on the constant md curves
# for i in range(len(contours_dm)):
# 	print('loop 3 i=', i)
# 	newrhocslist, newrhocdmlist = find_rhos(i)

# 	newproperties = np.zeros((len(newrhocslist), numprops+4))
# 	j=0
# 	for rhoc,rhocdm in zip(newrhocslist,newrhocdmlist):

# 		macro = tov([mu,P,cs2i,Rho],rhoc, rhocdm, props,stp,numpts,maxr,tol)
# 		newproperties[j] = [item for List in [[rhoc],[rhocdm],macro] for item in List] + [macro[props.index('Mdm')]+macro[props.index('M')],macro[props.index('Md')]/(macro[props.index('Mb')]+macro[props.index('Md')])]
# 		j = j+1
# 	dict_properties['contour_md'] = pd.DataFrame(newproperties, columns=headers)

# print('Printing the dictionary with all the contours')
# print(dict_properties.keys())
# print(dict_properties['contour_fdm'].keys())

# print(dict_properties['contour_md'].keys())
# # print(dict_properties)

# # # Change the file name or location
# # file_path = '/content/dict_properties.h5'


# # # Create the h5py file
# # hf = h5py.File(file_path, 'w')
# # hf.create_dataset('dataset_prop', data=dict_properties)
# # hf.close()

# # # Print a message confirming the dataset creation and file path
# # print('Dataset created successfully!')
# # print('Dataset saved to:', file_path)


# #
# #
# #
def save_dict_to_hdf5(dic, filename):

    with h5py.File(filename, 'w') as h5file:
        recursively_save_dict_contents_to_group(h5file, '/', dic)

def load_dict_from_hdf5(filename):

    with h5py.File(filename, 'r') as h5file:
        return recursively_load_dict_contents_from_group(h5file, '/')



def recursively_save_dict_contents_to_group( h5file, path, dic):

    # argument type checking
    if not isinstance(dic, dict):
        raise ValueError("must provide a dictionary")

    if not isinstance(path, str):
        raise ValueError("path must be a string")
    if not isinstance(h5file, h5py._hl.files.File):
        raise ValueError("must be an open h5py file")
    # save items to the hdf5 file
    for key, item in dic.items():
        #print(key,item)
        key = str(key)
        if isinstance(item, list):
            item = np.array(item)
            #print(item)
        if not isinstance(key, str):
            raise ValueError("dict keys must be strings to save to hdf5")
        # save strings, numpy.int64, and numpy.float64 types
        if isinstance(item, (np.int64, np.float64, str, np.float, float, np.float32,int)):
            #print( 'here' )
            h5file[path + key] = item
            if not h5file[path + key].value == item:
                raise ValueError('The data representation in the HDF5 file does not match the original dict.')
        # save numpy arrays
        elif isinstance(item, np.ndarray):
            try:
                h5file[path + key] = item
            except:
                item = np.array(item).astype('|S9')
                h5file[path + key] = item
            if not np.array_equal(h5file[path + key].value, item):
                raise ValueError('The data representation in the HDF5 file does not match the original dict.')
        # save dictionaries
        elif isinstance(item, dict):
            recursively_save_dict_contents_to_group(h5file, path + key + '/', item)
        # other types cannot be saved and will result in an error
        else:
            #print(item)
            raise ValueError('Cannot save %s type.' % type(item))

def recursively_load_dict_contents_from_group( h5file, path):

    ans = {}
    for key, item in h5file[path].items():
        if isinstance(item, h5py._hl.dataset.Dataset):
            ans[key] = item.value
        elif isinstance(item, h5py._hl.group.Group):
            ans[key] = recursively_load_dict_contents_from_group(h5file, path + key + '/')
    return ans
#
#
#


file_path = 'dict_properties.pickle'

# save_dict_to_hdf5(dict_properties,'test.hdf5')
with open(file_path, 'wb') as handle:
    pickle.dump(dict_properties, handle, protocol=pickle.HIGHEST_PROTOCOL)









# index = list(enumerate(dict_properties.keys()))

# df = pd.DataFrame(dict_properties)




# # Convert DataFrame to a nested dictionary
# nested_dict = df.to_dict(orient='records', index = index)

# # Convert nested dictionary to JSON
# json_data = pd.Series(nested_dict).to_json(orient='values')

# # Specify the file path where you want to save the JSON data
# file_path = '/content/dict_properties.json'

# # Save the nested dictionary as a JSON file
# with open(file_path, "w") as file:
#     json.dump(nested_dict, file)




# stable_md = []


# for i in range(len(dict_properties['contour_md'])):
# 	stable_md.append(find_max(dict_properties['contour_md']))


# stable_mb = []

# for i in range(len(dict_properties['contour_mb'])):
# 	stable_md.append(find_max(dict_properties['contour_mb']))


# stable = stable_mb + stable_md
# stable_sort = np.sort(stable, axis = 0)


# xdata = np.array([x[0] for x in stable])
# ydata = np.array([x[1] for x in stable])
# x,y = zip(*sorted(zip(xdata,ydata),key=lambda xdata: xdata[0]))



# # stable_line = np.polyfit(x,y,8)
# x1,y1 = np.array(list(x)), np.array(list(y))
# x2,y2 = x1.tolist(), y1.tolist()
# xnew = np.linspace(0,20, 60, endpoint = True)
# xnew2 =np.linspace(5.4,10.3, 60, endpoint = True)


# def func(x, a, b,c,d,e):
#     return a*np.power(x,4) + b*np.power(x,3) + c*np.power(x,2) + d*x + e
# popt, pcov = curve_fit(func, x1, y1)
# func(x1, *popt)

# def func_new(x, a,b,c,d,e):

#   return np.piecewise(x, [x < min(x1), (x>= min(x1)) & (x< 1.1*max(x1)), x >= 1.1*max(x1)], [2.5,lambda x: func(x,a,b,c,d,e), 2.5])



# def stable_crop(file,col,frac, a,b,c,d,e):
#   stable_curves = []
#   boolean_array = file['Mg'] < func_new(file['R'],a,b,c,d,e)
#   # print(boolean_array)
#   boolean_new = []
#   boolean_element = boolean_array[0]
#   # print(boolean_array)
#   i=0
#   while boolean_element == True and i<len(boolean_array):
#     boolean_element = boolean_array[i]
#     boolean_new.append(boolean_element)
#     i=i+1
#   while i < len(boolean_array):
#     boolean_new.append(False)
#     i = i+1
#   boolean_array = boolean_new
#   # print(boolean_array)

#   for i in range(len(boolean_array)):

#     if boolean_array[i] == True:
#       R,M = file['R'][i], file['Mg'][i]
#       stable_curves.append((R,M))
#       plt.plot(file['R'][i], file['Mg'][i],lw=1, marker = '.', c = col,label = '{}%'.format(frac) if i == 0 else "" )

#     elif boolean_array[i] == False:
#       R,M = file['R'][i], file['Mg'][i]
#       # print(R, M, func(file['R'][i],a,b,c,d,e))


#     # if file['M'] < func(file['R'], a,b,c,d,e):
#     #   plt.scatter(file['R'], file['Mg'],marker='.',s=3, c = 'b' )
#     # else:
#     #   plt.scatter(file['R'], file['Mg'],marker='.',s=3, c = 'r' )


#   return stable_curves


# plt.scatter([ x[0] for x in stable], [ x[1] for x in stable])
# plt.plot(xnew, func_new(xnew, *popt), 'r-')
# plt.savefig('maxlines.png')
